#!/usr/bin/env python

import asyncio
import json
import os
import subprocess
import sys

import magic
import requests
from playwright.async_api import (
    async_playwright,
    Error as PlaywrightError,
    TimeoutError as PlaywrightTimeoutError,
)

from utils import (
    script_directory,
    die,
    log,
    warn,
)


MAX_TASKS = 5
VALID_TYPES = [
    "image/jpeg",
    "image/png",
    "image/gif",
    "image/webp",
]


def resize_image(path):
    subprocess.Popen(["convert", "-quality", "50%", "-resize", "x320", path, path])


async def get_social_image(page):
    """
    Return a bytes object containing purportedly valid image data or None
    """
    # Find at most ONE image url
    image_url = None
    for sel, attr in {
        'meta[property="og:image"]': "content",
        'meta[name="twitter:image"]': "content",
        'link[rel="image_src"]': "href",
        'link[as="image"]': "href",
        'meta[itemprop="thumbnailUrl"]': "content",
        'meta[itemprop="image"]': "content",
    }.items():
        try:
            locator = page.locator(f"css={sel}")
            if image_url := await locator.get_attribute(attr, timeout=100):
                break
        except PlaywrightTimeoutError:
            continue

    # Download and check the validity of the image
    if image_url:
        try:
            r = requests.get(image_url)
        except requests.RequestException:
            return
        if magic.from_buffer(r.content, mime=True) in VALID_TYPES:
            return r.content


async def make_preview(browser, device, url, output_path):
    # Basic sanity check prevents overwriting non-images
    log(f"get: {url}")
    if os.path.isfile(output_path):
        if magic.from_file(output_path, mime=True) not in VALID_TYPES:
            warn(f"preview: not overwriting {output_path}")
            return

    try:
        context = await browser.new_context(**device)
        page = await context.new_page()
        await page.goto(url)

        # First we try downloading a social image
        if image_data := await get_social_image(page):
            with open(output_path, "wb") as f:
                f.write(image_data)
                resize_image(output_path)
                log(f"preview: downloaded preview {output_path}")
            return

        # Otherwise we'll render an image
        try:
            await page.screenshot(path=output_path, type="jpeg", timeout=10000)
            resize_image(output_path)
            log(f"preview: generated preview {output_path}")
        except PlaywrightTimeoutError:
            warn(f"preview: failed to generate {output_path}")

    except PlaywrightError:
        warn(f"preview: couldn't load {url}")

    finally:
        await context.close()


async def main(urls_and_outputs):
    log("playwright: starting up...")
    playwright = await async_playwright().start()
    browser = await playwright.chromium.launch()
    device = playwright.devices["Desktop Chrome"]

    async def sem_locked_coroutine(coroutine):
        async with semaphore:
            return await coroutine

    semaphore = asyncio.Semaphore(MAX_TASKS)
    coroutines = (
        make_preview(browser, device, url, output_path)
        for url, output_path in urls_and_outputs.items()
    )
    await asyncio.gather(*(sem_locked_coroutine(c) for c in coroutines))

    await browser.close()
    await playwright.stop()
    log("preview: finished")


if __name__ == "__main__":
    if len(sys.argv) != 2:
        die(
            f"preview: Usage: {os.path.basename(sys.argv[0])} JSON_MAPPING_OF_URLS:OUTPUTS"
        )

    try:
        urls_and_outputs = json.loads(sys.argv[1])
    except json.decoder.JSONDecodeError:
        die("preview: unable to load json mapping of urls to output files")

    with script_directory():
        loop = asyncio.get_event_loop()
        loop.run_until_complete(main(urls_and_outputs))
