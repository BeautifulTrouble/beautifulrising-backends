#!/usr/bin/env python3
#encoding: utf-8

import autovenv
autovenv.run()

import json
import os
import pprint
import re
import sys
from functools import cmp_to_key
from operator import attrgetter, itemgetter
from urllib.parse import urlparse, unquote

import couchdb
import requests
from cerberus import Validator
from couchdb.http import ResourceNotFound
from flask import Flask, Response, request, url_for
from flask_compress import Compress
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from flask_restful import Resource, Api
from icu import Locale, RuleBasedCollator
from werkzeug.exceptions import NotFound, Forbidden

from utils import *
from config import *


# App Setup
# ////////////////////////////////////////////////////////////////////////////

app = Flask(__name__)
api = Api(app)
Compress(app)
limiter = Limiter(app, key_func=get_remote_address)


# CouchDB Setup
# ////////////////////////////////////////////////////////////////////////////

couch = couchdb.Server()
db = couch[DB_NAME]


class CouchDocumentAccessor(object):
    def __init__(self, id):
        self.id = id
    def __getitem__(self, item):
        return self.get(item)
    def get(self, item, default=''):
        return db[self.id].get(item, default)
    def items(self):
        return db[self.id].items()
config = CouchDocumentAccessor('config:api')


# Google administrative mumbo jumbo
# ////////////////////////////////////////////////////////////////////////////

@app.route('/' + GOOGLE_VERIFICATION)
def google_verification():
    '''
    Keep the googles happy
    '''
    return 'google-site-verification: {}'.format(GOOGLE_VERIFICATION)


# Drive change notification
# ////////////////////////////////////////////////////////////////////////////

@app.route(API_NOTIFICATION_PATH, methods=['POST'])
def notify():
    '''
    Invoke content loader upon change notification
    '''
    header = lambda name: request.headers.get(name, '')

    # Before doing anything, verify the notification token
    if header('X-Goog-Channel-Token') != API_NOTIFICATION_TOKEN:
        raise Forbidden

    state = header('X-Goog-Resource-State')
    channel_id = header('X-Goog-Channel-Id')
    resource_id = header('X-Goog-Resource-Id')

    # Save new notification ids so they can be cancelled
    if state == 'sync':
        log("sync: Channel-Id: {} Resource-Id: {}".format(channel_id, resource_id))
        try:
            channels = db['config:notification-channels']
            channels[channel_id] = resource_id
        except ResourceNotFound:
            channels = {channel_id: resource_id}
            channels.update(_id='config:notification-channels', type='config', slug='notification-channels')
        db.save(channels)

    # Notify that a document is no longer in the collection
    # TODO: new document tracking system by id
    elif state == 'delete':
        print('delete', request.get_json())
        # XXX: venv_run("contentloader", "--delete-id", doc_id)

    # Attempt to invoke the content loader
    elif state == 'change':
        log("changed: Channel-Id: {} Resource-Id: {}".format(channel_id, resource_id))
        body = request.get_json()
        if body:
            with script_directory():
                change_number = str(int(body['id']))
                venv_run("contentloader", "--change-id", change_number)

    return '', 204


# Intake
# ////////////////////////////////////////////////////////////////////////////

def recaptcha_is_valid(recaptcha_response, recaptcha_version, *, timeout=4):
    '''
    Validate a recaptcha from form data. Always returns True if DEBUG is True.
    '''
    if DEBUG:
        return True

    if recaptcha_version == 'v2':
        log('recaptcha: v2')
        secret = RECAPTCHA_V2_SITE_SECRET
    else:
        log('recaptcha: invisible')
        secret = RECAPTCHA_INVISIBLE_SITE_SECRET

    try:
        return requests.post('https://www.google.com/recaptcha/api/siteverify', timeout=timeout, data={
            'secret': secret,
            'response': recaptcha_response,
            'remoteip': request.remote_addr,
        }).json().get('success')
    except requests.RequestException: pass


@app.route('/intake/<feature>', methods=['POST'])
@limiter.limit(API_INTAKE_LIMIT)
def intake(feature):
    feature_requirements = {
        'contributor-question': Validator({
            'contributors':     {'type': 'list', 'schema': {'type': 'string'}},
            'question':         {'type': 'string', 'required': True},
        }),
        'real-world-examples': Validator({
            'document_title':   {'type': 'string', 'required': True},
            'document_link':    {'type': 'string', 'required': True},
            'title':            {'type': 'string', 'required': True},
            'link':             {'type': 'string', 'required': True},
            'description':      {'type': 'string', 'required': True},
        }),
        'newsfeed-suggestion': Validator({
            'suggestion':       {'type': 'string', 'required': True},
        }),
        'resource-suggestion': Validator({
            'title':            {'type': 'string', 'required': True},
            'link':             {'type': 'string', 'required': True},
            'description':      {'type': 'string', 'required': True},
        }),
    }
    body = request.get_json()
    if recaptcha_is_valid(body.pop('g-recaptcha-response', None), body.pop('g-recaptcha-version', None)):
        validator = feature_requirements.get(feature)
        if validator is not None and validator.validate(body):
            extra = config.get('private', {}).get('notification-emails', [ADMIN_EMAIL])
            if DEBUG:
                extra = [ADMIN_EMAIL]
            args = map(json.dumps, (body, extra))
            venv_run('intakehandler', feature, *args)
            return '', 204
    schema = pprint.pformat(dict(validator.schema))
    return 'Validation Failed. Use reCAPTCHA and the following schema:\n{}'.format(schema), 400


# Output filtering
# ////////////////////////////////////////////////////////////////////////////

# Used for setting module-type
module_types = [t['one'] for t in config['types-modules']]

# Cache the locale-specific comparator key functions
comparators = {L: cmp_to_key(RuleBasedCollator.createInstance(Locale(L)).compare)
               for L in config['language-all']}

def filter_output(resources):
    '''
    Filter the output by language, merge x-language keys, and hide keys
    '''
    # Allow passing in a single resource to get a single resource back
    single = False
    if isinstance(resources, dict):
        single = True
        resources = [resources]

    language_all = config['language-all']
    language_add = config['language-add']
    language_default = config['language-default']
    language_remove = set(config['language-remove'])
    language_ignore_missing = language_remove | {
        # Added during standard processing
        'lang', 'type', 'title', 'slug', 'timestamp',
        'document_id', 'document_link', 'document_title',
        # Added during custom filtering
        'byline'
    }

    # Get one valid language no matter what
    lang = request.args.get('lang')
    if lang not in language_all:
        lang = language_default

    # Identify the keys which should be hidden from the API
    # HTTPS/localhost connections can circumvent w/an X-API-Admin-Token: header
    if request.headers.get('x-api-admin-token') == API_ADMIN_TOKEN:
        private_keys = {}
    else:
        private_keys = {T['one']: T['private'].split() for T in config['types'] if 'private' in T}

    output = []
    for resource in resources:
        # Remove the translations for overlaying or discarding
        translations = resource.pop('translations', {})
        translated = translations.get(lang)

        if lang == language_default:
            # Default language has no lang-missing
            language_present = set(resource.keys())

        elif translated:
            # Keep track of the keys which are present in this translation
            language_present = set(translated.keys())

            # Hold these items to be re-added after resource.update
            preserved = {k:v for k,v in resource.items() if k in language_add}
            # Default language content it here overwritten with translated content
            resource.update({k:v for k,v in translated.items() if k not in language_remove})
            # Preserved content (from language_add keys) is here added back in
            for k,item_in_default_language in preserved.items():
                # Merge one level of nested lists
                if isinstance(resource[k], list) and isinstance(item_in_default_language, list):
                    resource[k] += [item for item in item_in_default_language if item not in resource[k]]
            # I believe this sets lang for pieces where the translations were created
            # artificially (using suffixed keys) and lang isn't present. If that's the
            # case it probably belongs in the contentloader because this won't be accurate
            resource['lang'] = lang

        else:
            # This is an untranslated piece
            language_present = set()
        
        # Remove private keys
        if 'type' in resource and resource['type'] in private_keys:
            for key in private_keys[resource['type']]:
                resource.pop(key, None)
        resource.pop('private', None)

        # Produce a proper list of all lang-missing keys. This requires taking into account
        # all of the keys generated by the contentloader which may not be present when a
        # translated document is generated only from language-suffixed keys.
        resource['lang-missing'] = lang_missing = [k for k in (
                set(resource.keys())
                - {resource['type']}
                - language_present
                - language_ignore_missing
            ) if not k.startswith('_')]

        # Produce an effective module type based on lang-missing
        # The module-type is initially produced by the document title in the contentloader
        # but may be effectively a lesser type when portions are missing from translation.
        if resource['type'] in module_types:
            module_type = module_type_effective = resource['module-type']
            document_title = resource['document_title']
            # We have to be sure not to promote a piece to gallery if it's meant to be a
            # snapshot but has a full-write-up in language_default and possibly has
            # 'full-write-up' in lang_missing. Team ed. wants the filename to set the type.
            if module_type == 'full' and 'full-write-up' in lang_missing:
                module_type_effective = 'gallery'
            if 'short-write-up' in lang_missing:
                module_type_effective = 'snapshot'
            if 'snapshot' in lang_missing:
                module_type_effective = 'untranslated'
                # This relates to the comment above about the lang attribute. An underlying
                # assumption here might be that an untranslated piece means the original is
                # in English and that is not necessarily always true.
                resource['lang'] = language_default
            resource['module-type-effective'] = module_type_effective

        # List available languages
        resource['langs-available'] = list(translations.keys() | {language_default})

        output.append(resource)

    # Return an dict or list of dicts as appropriate
    if single:
        output = output or [{}]
        return output[0]

    # Allow sorting by query param 'orderby=keyname' (if possible)
    try:
        orderby = request.args.get('orderby', 'title')
        keyfunc = lambda obj: comparators[lang](str(obj.get(orderby, '')))
        reverse = request.args.get('reverse', '').lower() == 'true'
        output = sorted(output, key=keyfunc, reverse=reverse)
    except: pass

    # Allow basic pagination by query params 'limit=N_per_page&page=N'
    # A sentinel value of [current_page, total_pages] appears at the end
    try:
        limit = abs(int(request.args['limit']))
        page = abs(int(request.args.get('page', 1)))
        total = len(output) // limit + bool(len(output) % limit)
        output = output[(page-1) * limit: (page-1) * limit + limit] + [[page, total]]
    except: pass
    else:
        if not 0 < page <= total:
            raise NotFound

    return output


# API Endpoints
# ////////////////////////////////////////////////////////////////////////////

@app.after_request
def add_cors_headers(response):
    '''
    Tell browsers it's okay to load from this resource
    '''
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET')
    return response


# Get content types and create endpoints
types = {T['one']: T['many'] for T in config['types']}
for singular_name,plural_name in types.items():

    class Many(Resource):
        type = singular_name
        query = "function(doc){if(doc.type=='%s'){emit(doc.slug,doc)}}" % singular_name
        def get(self):
            try:
                return filter_output([doc['value'] for doc in db.query(self.query)])
            except (KeyError, ResourceNotFound): raise NotFound
    api.add_resource(Many, '{API_PATH}/{plural_name}'.format(**vars()), endpoint=plural_name)

    class One(Resource):
        type = singular_name
        def get(self, id):
            try:
                return filter_output(db['{}:{}'.format(self.type, id)])
            except ResourceNotFound: raise NotFound
    api.add_resource(One, '{API_PATH}/{singular_name}/<id>'.format(**vars()), endpoint=singular_name)


# Get the grouped types and create endpoints
groups = {k.split('-',1)[-1]:[d['one'] for d in v] for k,v in config.items() if k.startswith('types-')}
for group,types in groups.items():

    class Group(Resource):
        types = types
        query = "function(doc){if(%s.indexOf(doc.type)!=-1){emit(doc.slug,doc)}}" % json.dumps(types)
        def get(self):
            try:
                return filter_output([doc['value'] for doc in db.query(self.query)])
            except (KeyError, ResourceNotFound): raise NotFound
    api.add_resource(Group, '{API_PATH}/{group}'.format(**vars()), endpoint=group)


# Just emit all the documents
class All(Resource):
    query = "function(doc){emit(doc.slug,doc)}"
    def get(self):
        try:
            return filter_output([doc['value'] for doc in db.query(self.query)])
        except (KeyError, ResourceNotFound): raise NotFound
api.add_resource(All, '{API_PATH}/all'.format(**vars()), endpoint='all')


# Expose the config for front-ends
class Config(Resource):
    def get(self):
        return filter_output(dict(config.items()))
api.add_resource(Config, '{API_PATH}/config'.format(**vars()))


# Expose the endpoints themselves
class Endpoints(Resource):
    def get(self):
        return {rule.endpoint: {
                'url': unquote(url_for(rule.endpoint, **{a: '<{}>'.format(a) for a in rule.arguments})),
                'methods': list(rule.methods),
            } for rule in app.url_map.iter_rules()}
api.add_resource(Endpoints, '{API_PATH}'.format(**vars()))


# Run when invoked from the command line
# ////////////////////////////////////////////////////////////////////////////

if __name__ == '__main__':
    app.run(port=6000 + DEBUG + DEVELOP, debug=DEBUG)


