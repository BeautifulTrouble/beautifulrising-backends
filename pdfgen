#!/usr/bin/env python

import re
import time
from datetime import timedelta
from hashlib import md5
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup
from quart import Quart, Response, request
from quart_rate_limiter import RateLimiter, RateLimit
from jinja2 import Template
from markdown import markdown as markdown_
from playwright.async_api import async_playwright
from plucky import plucks

from utils import (
    log,
    script_directory,
    script_subdirectory,
    slugify,
)
from config import (
    API_PATH,
    API_SERVER,
)

ABSOLUTE_URL_PREFIX = "https://beautifultrouble.org"
RELATIVE_URL_REGEX = re.compile("^/tool/.+")
TAG_URL = urljoin(ABSOLUTE_URL_PREFIX, "/tag/%s")
TOOL_URL = urljoin(ABSOLUTE_URL_PREFIX, "/tool/%s")
TYPE_ORDER = "story", "tactic", "principle", "theory", "methodology"

PDF_CACHE_LIFESPAN = 1440 * 60
PDF_API_CACHE_LIFESPAN = 60 * 60


app = Quart(__name__)

# Limit is 10 requests / minute
limiter = RateLimiter(app, default_limits=[RateLimit(10, timedelta(minutes=1))])

config = requests.get(f"{API_SERVER}{API_PATH}/config").json()


@app.before_serving
async def startup():
    global browser, playwright
    playwright = await async_playwright().start()
    browser = await playwright.chromium.launch()


@app.after_serving
async def shutdown():
    await browser.close()
    await playwright.stop()


def markdown(s, p=True):
    """
    Render markdown and filter content which is inappropriate for display in
    PDFs. Images are stripped and relative links made absolute.
    """

    if not s:
        return ""

    s = re.sub(r"([^\n])\n([^\n])", r"\1\n\n\2", s)
    html = markdown_(
        s, output_format="html5", extensions=["markdown.extensions.footnotes"]
    )
    soup = BeautifulSoup(html, "html.parser")

    # Strip images
    for img in soup.findAll("img"):
        img.extract()

    # Make relative links absolute
    for rel_link in soup.findAll("a", href=RELATIVE_URL_REGEX):
        rel_link.attrs["href"] = urljoin(ABSOLUTE_URL_PREFIX, rel_link.attrs["href"])

    html = str(soup)

    if not p:
        html = re.sub(r"^\s*<p>", "", html)
        html = re.sub(r"</p>\s*$", "", html)

    return html


def get_modules_people_and_text(module_slugs, lang, *, cache={}):
    """
    Get (cached) modules, people and text.
    `modules` returned are the requested subset
    `people` is the entire collection of people
    `text` is a select subset of needed strings
    """

    # Only fetch API data once per PDF_API_CACHE_LIFESPAN per language
    now = time.time()
    c = cache.setdefault(lang, {})

    if now - c.get("last_request", 0) > PDF_API_CACHE_LIFESPAN:
        content = requests.get(f"{API_SERVER}{API_PATH}/all?lang={lang}").json()

        c["people"] = {o.get("slug"): o for o in content if o.get("type") == "person"}
        c["texts"] = {o.get("slug"): o for o in content if o.get("type") == "text"}

        # Prepare the relevant pieces of translation
        text = c["text"] = {}
        text["contributed"] = plucks(c["texts"], "ui.module.contributed-by")
        text["learn"] = plucks(c["texts"], "ui.module.learn-more")
        text["module"] = plucks(c["texts"], "ui.module")
        text["related"] = plucks(c["texts"], "ui.module.related-modules")
        text["risks"] = plucks(c["texts"], "ui.module.potential-risks")
        text["tags"] = plucks(c["texts"], "ui.module.tags")
        text["types"] = plucks(c["texts"], "ui.types")
        text["how"] = plucks(c["texts"], "ui.module.how-to-use")
        # Get key-whatever translations in singular & plural
        text["key"] = {
            p: [
                plucks(c["texts"], "ui.module.key-" + s),
                plucks(c["texts"], "ui.module.key-" + p),
            ]
            for s, p in config["plural-name-for-type"].items()
        }
        # Produce table of tag translations
        text["tagtext"] = {
            slugify(k): (TAG_URL % slugify(k), v.capitalize())
            for k, v in plucks(c["texts"], "tags.all").items()
        }

        # Preprocess the modules for easier use in template rendering
        module_types = [t["one"] for t in config["types-tool"]]
        modules = c["modules"] = {
            o.get("slug"): o for o in content if o.get("type") in module_types
        }
        titles = c["titles"] = {k: v.get("title") for k, v in c["modules"].items()}

        # Is there another way to ensure that these split strings always have two elements?
        episplit = lambda s: re.split(r"\s+[—–―-](?=[^—–―-]+$)", s) + [""]
        keysplit = lambda s: re.split(r"\s+[—–―-]\s+", s) + [""]

        for slug, m in modules.items():
            m["tags"] = [slugify(t) for t in m.get("tags", [])]
            m["epigraphs"] = [episplit(e) for e in m.get("epigraphs", [])]
            for type_ in text["key"]:
                m["key-" + type_] = [keysplit(k) for k in m.get("key-" + type_, [])]
            # Replace related module slugs with (url, title)
            for type_ in text["key"]:
                if type_ in m:
                    m[type_] = [(TOOL_URL % s, titles.get(s, s)) for s in m[type_]]

        c["last_request"] = now
        log(f"pdfgen: fetching {lang} modules")

    # When no module_slugs are provided, all modules are used
    if not module_slugs:
        module_slugs = c["modules"].keys()

    # Remove duplicates
    module_slugs = set(module_slugs)

    # Unsorted modules are picked from the collection by slug
    modules = [c["modules"][slug] for slug in module_slugs if slug in c["modules"]]

    # Modules are sorted by title and grouped by type
    modules_by_type = {
        t: sorted([m for m in modules if m["type"] == t], key=lambda m: m["title"])
        for t in TYPE_ORDER
    }

    # The final ordered list is created as a sequence of typed groups
    modules_ordered = []
    for t in TYPE_ORDER:
        modules_ordered.extend(modules_by_type[t])

    return modules_ordered, c["people"], c["text"]


async def make_pdf(modules, lang, paper_size, unique_hash, *, last_generation={}):
    """
    Produce a bytes object containing a PDF rendered by headless chromium
    """
    now = time.time()
    if now - last_generation.get(unique_hash, 0) < PDF_CACHE_LIFESPAN:
        try:
            with script_subdirectory("pdfcache"):
                with open(f"{unique_hash}.pdf", "rb") as f:
                    log("pdfgen: sending cached pdf")
                    return f.read()
        except OSError:
            pass
    last_generation[unique_hash] = now

    type_order = [config["plural-name-for-type"][t] for t in TYPE_ORDER]
    modules, people, text = get_modules_people_and_text(modules, lang)
    log(f"pdfgen: generating pdf of {len(modules)} module(s)")

    with script_directory():
        with open("pdftemplate.html") as f:
            template = Template(f.read(), extensions=["jinja2.ext.loopcontrols"])
        html = template.render(markdown=markdown, **__builtins__.__dict__, **vars())

        with script_subdirectory("pdfcache") as directory:
            with open(f"{directory}/{unique_hash}.html", "w") as f:
                f.write(html)

            context = await browser.new_context()
            page = await context.new_page()
            await page.goto(f"file:///{directory}/{unique_hash}.html")
            # await page.emulate_media(media="screen")
            await page.pdf(
                format="Letter" if paper_size == "letter" else "A4",
                margin={
                    "top": "0.5in",
                    "bottom": "0.5in",
                    "left": "0.5in",
                    "right": "0.5in",
                },
                path=f"{directory}/{unique_hash}.pdf",
            )
            await context.close()

            with open(f"{directory}/{unique_hash}.pdf", "rb") as f:
                return f.read()


@app.route("/pdf/download", methods=["GET"])
async def pdf():
    """
    Optional query parameters:
        tools=flash-mob tools=flash-mob,divestment (defaulting to all)
        lang=en (defaulting to language-default from the config)
        size=a4 size=letter (defaulting to letter)
        save=true (force "content-disposition: attachment" header)

    Thus, a valid GET might look like any of these:
        /pdf/download (all tools)
        /pdf/download?tools=divestment&size=a4
    """

    tools = request.args.get("tools")
    tools = tools.split(",") if tools else []

    lang = request.args.get("lang", "")
    if lang not in config["language-all"]:
        lang = config["language-default"]

    size = request.args.get("size", "")
    if size not in ("a4", "letter"):
        size = "letter"

    save = request.args.get("save", "")

    # Create a unique hash of the PDF's specifics
    unique = f"{sorted(set(tools))}{lang}{size}"
    unique_hash = md5(unique.encode()).hexdigest()
    unique_filename = (
        f'Beautiful-Trouble_{len(tools) or "all"}-tools_{unique_hash[:5]}.pdf'
    )

    return Response(
        await make_pdf(tools, lang, size, unique_hash),
        mimetype="application/pdf",
        headers={
            "Content-Disposition": f'{"attachment; " if save else ""}filename="{unique_filename}"'
        },
    )


if __name__ == "__main__":
    app.run(port=6005)
